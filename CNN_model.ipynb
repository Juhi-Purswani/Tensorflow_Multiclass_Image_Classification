{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Juhi-Purswani/Tensorflow_Multiclass_Image_Classification/blob/master/CNN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibY-eM59u-Ba",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "ed538874-d210-48a0-a655-ae63ad832614"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXvx99kUyA1P",
        "colab_type": "code",
        "outputId": "dfb1b709-0355-4599-cdbb-fd31958ff724",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiuEGrHnyMu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"./drive/My Drive/Plant_Seedlings\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uYXoXRYyVDD",
        "colab_type": "code",
        "outputId": "39155563-7391-4ffb-830b-d1097c1f4ecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUr2iziFyX8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 48\n",
        "CHANNELS = 3\n",
        "TRAIN_DIR = 'plant_seedlings'\n",
        "#TEST_DIR = ''\n",
        "batch_size = 128\n",
        "learning_rate = 0.001\n",
        "training_iters = 20\n",
        "n_classes = 12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqxVxuEPyt1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_features_labels(DIR):\n",
        "  features = []\n",
        "  labels = []\n",
        "  dir_number = 0\n",
        "  car_names = os.listdir(DIR)\n",
        "  for name in car_names:\n",
        "    path = DIR + '/' + name\n",
        "    print(\"dir name and number\" , path , 'and',dir_number)\n",
        "    print(path)\n",
        "    image_names = os.listdir(path)\n",
        "    for image_name in image_names:\n",
        "      image_path = path + '/' + image_name\n",
        "      img = cv2.imread(image_path,cv2.IMREAD_COLOR)\n",
        "      img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n",
        "      features.append(img)\n",
        "      labels.append(np.array(dir_number))\n",
        "    dir_number = dir_number + 1\n",
        "  return(features , labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp70MdcdywsU",
        "colab_type": "code",
        "outputId": "bf2147db-50a1-4936-96d2-409a9370dcf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "train_features,train_labels = create_features_labels(TRAIN_DIR)\n",
        "#test_features,test_labels = create_features_labels(TEST_DIR)\n",
        "train_features = np.asarray(train_features).reshape(-1,IMG_SIZE,IMG_SIZE,CHANNELS)\n",
        "#test_features = np.asarray(test_features).reshape(-1,IMG_SIZE,IMG_SIZE,CHANNELS)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dir name and number plant_seedlings/Scentless Mayweed and 0\n",
            "plant_seedlings/Scentless Mayweed\n",
            "dir name and number plant_seedlings/Loose Silky-bent and 1\n",
            "plant_seedlings/Loose Silky-bent\n",
            "dir name and number plant_seedlings/Common wheat and 2\n",
            "plant_seedlings/Common wheat\n",
            "dir name and number plant_seedlings/Charlock and 3\n",
            "plant_seedlings/Charlock\n",
            "dir name and number plant_seedlings/Sugar beet and 4\n",
            "plant_seedlings/Sugar beet\n",
            "dir name and number plant_seedlings/Small-flowered Cranesbill and 5\n",
            "plant_seedlings/Small-flowered Cranesbill\n",
            "dir name and number plant_seedlings/Cleavers and 6\n",
            "plant_seedlings/Cleavers\n",
            "dir name and number plant_seedlings/Fat Hen and 7\n",
            "plant_seedlings/Fat Hen\n",
            "dir name and number plant_seedlings/Common Chickweed and 8\n",
            "plant_seedlings/Common Chickweed\n",
            "dir name and number plant_seedlings/Shepherd’s Purse and 9\n",
            "plant_seedlings/Shepherd’s Purse\n",
            "dir name and number plant_seedlings/Maize and 10\n",
            "plant_seedlings/Maize\n",
            "dir name and number plant_seedlings/Black-grass and 11\n",
            "plant_seedlings/Black-grass\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAg5W9zGAeHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features, labels = shuffle(train_features,train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejyES1Wxyz6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = np.asarray(labels)\n",
        "#test_labels = np.asarray(test_labels)\n",
        "labels = to_categorical(labels)\n",
        "#test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TOaKaOVy175",
        "colab_type": "code",
        "outputId": "775476fb-bcf2-42aa-e4e3-f8e0e18fd154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(features.shape,labels.shape)\n",
        "#print(test_features.shape,test_labels.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5555, 48, 48, 3) (5555, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-xCqM6q3nDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G1HaYn5SkC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = (X_train/np.float32(255))\n",
        "X_test = X_test/np.float32(255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEGPTe4Hy7aq",
        "colab_type": "code",
        "outputId": "af76ebec-eb48-492f-c5b4-784cafda9271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "x = tf.placeholder(\"float\",[None,IMG_SIZE,IMG_SIZE,CHANNELS])\n",
        "y = tf.placeholder(\"float\",[None,n_classes])\n",
        "\n",
        "conv1 = tf.layers.conv2d(inputs=x,filters=64,kernel_size=[3,3],padding=\"same\",activation =tf.nn.relu)\n",
        "pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=[2,2],strides=2)\n",
        "conv2 = tf.layers.conv2d(inputs=pool1,filters=32,kernel_size=[3,3],padding=\"same\",activation=tf.nn.relu)\n",
        "pool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=[2,2],strides=2)\n",
        "pool3_flat = tf.reshape(pool2,[-1,12*12*32])\n",
        "dense1 = tf.layers.dense(inputs=pool3_flat,units=1000,activation=tf.nn.relu)\n",
        "dense2 = tf.layers.dense(inputs=dense1,units=100,activation=tf.nn.relu)\n",
        "out = tf.layers.dense(inputs=dense2,units=12,activation=tf.nn.relu)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0626 20:04:14.653310 139812096583552 deprecation.py:323] From <ipython-input-13-1d7460cc66c5>:4: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "W0626 20:04:14.666306 139812096583552 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0626 20:04:15.097955 139812096583552 deprecation.py:323] From <ipython-input-13-1d7460cc66c5>:5: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.MaxPooling2D instead.\n",
            "W0626 20:04:15.270048 139812096583552 deprecation.py:323] From <ipython-input-13-1d7460cc66c5>:9: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23nNhxGtzAHB",
        "colab_type": "code",
        "outputId": "39bdb2f1-077f-4a21-9ca7-4d6004677824",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = out,labels = y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "#Two more nodes for accuray evaluation\n",
        "correct_prediction = tf.equal(tf.argmax(out,1),tf.argmax(y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0626 20:04:17.093565 139812096583552 deprecation.py:323] From <ipython-input-14-827d028d1050>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuUNN1rGzEtd",
        "colab_type": "code",
        "outputId": "8633aab3-caf0-4b17-d2d0-03e5e687c175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    train_loss = []\n",
        "    train_accuracy = []\n",
        "    #summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
        "    for i in range(training_iters):\n",
        "        for batch in range(len(train_features)//batch_size):\n",
        "            batch_x = X_train[batch*batch_size:min((batch+1)*batch_size,len(X_train))]\n",
        "            batch_y = y_train[batch*batch_size:min((batch+1)*batch_size,len(y_train))]\n",
        "            #print(batch_x.shape,batch_y.shape)\n",
        "            a,b,c,d = batch_x.shape\n",
        "            if(a==0):\n",
        "              break\n",
        "            opt = sess.run(optimizer, feed_dict={x: batch_x,y: batch_y})\n",
        "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x, y: batch_y})\n",
        "        print(\"the \", i , \"th iteration with loss: \" , loss, \" and accuracy: \", acc)\n",
        "        #print(\"_____________________________________________________________\")\n",
        "        #print(loss)\n",
        "        #print(\"_____________________________________________________________\")\n",
        "        train_loss.append(loss)\n",
        "        train_accuracy.append(acc)\n",
        "    #summary_writer.close()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the  0 th iteration with loss:  2.2944124  and accuracy:  0.27173913\n",
            "the  1 th iteration with loss:  2.0926876  and accuracy:  0.38043478\n",
            "the  2 th iteration with loss:  1.758475  and accuracy:  0.4456522\n",
            "the  3 th iteration with loss:  1.6105422  and accuracy:  0.5326087\n",
            "the  4 th iteration with loss:  1.4820217  and accuracy:  0.59782606\n",
            "the  5 th iteration with loss:  1.3846036  and accuracy:  0.6413044\n",
            "the  6 th iteration with loss:  1.2686042  and accuracy:  0.6413044\n",
            "the  7 th iteration with loss:  1.1702846  and accuracy:  0.6630435\n",
            "the  8 th iteration with loss:  1.1028937  and accuracy:  0.6630435\n",
            "the  9 th iteration with loss:  1.0932964  and accuracy:  0.6630435\n",
            "the  10 th iteration with loss:  1.019954  and accuracy:  0.6847826\n",
            "the  11 th iteration with loss:  0.98421794  and accuracy:  0.6956522\n",
            "the  12 th iteration with loss:  0.94190794  and accuracy:  0.6956522\n",
            "the  13 th iteration with loss:  0.92762136  and accuracy:  0.6956522\n",
            "the  14 th iteration with loss:  0.9324627  and accuracy:  0.67391306\n",
            "the  15 th iteration with loss:  0.90275  and accuracy:  0.6956522\n",
            "the  16 th iteration with loss:  0.8491153  and accuracy:  0.6956522\n",
            "the  17 th iteration with loss:  0.8115425  and accuracy:  0.70652175\n",
            "the  18 th iteration with loss:  0.80027556  and accuracy:  0.70652175\n",
            "the  19 th iteration with loss:  0.82054555  and accuracy:  0.6956522\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}